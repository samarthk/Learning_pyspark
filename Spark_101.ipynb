{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Spark_101.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1pyZxLcvgjKs45Nez-scJCXpS51JmcHHt",
      "authorship_tag": "ABX9TyNxS6dfvwaLeicK9htRbzU8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samarthk/Learning_pyspark/blob/master/Spark_101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xt8tgg_1wBKA",
        "colab_type": "text"
      },
      "source": [
        "# Install Java, Spark, and Findspark\n",
        "This installs Apache Spark 2.3.1, Java 8, and [Findspark](https://github.com/minrk/findspark), a library that makes it easy for Python to find Spark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQXZkWnov1aC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5aacb9ea-0c28-4fb8-fab7-d7cdf4be1a01"
      },
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-2.4.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-14 12:14:13--  https://archive.apache.org/dist/spark/spark-2.4.1/spark-2.4.1-bin-hadoop2.7.tgz\n",
            "Resolving archive.apache.org (archive.apache.org)... 138.201.131.134, 2a01:4f8:172:2ec5::2\n",
            "Connecting to archive.apache.org (archive.apache.org)|138.201.131.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 230778742 (220M) [application/x-gzip]\n",
            "Saving to: ‘spark-2.4.1-bin-hadoop2.7.tgz’\n",
            "\n",
            "spark-2.4.1-bin-had 100%[===================>] 220.09M  23.4MB/s    in 11s     \n",
            "\n",
            "2020-06-14 12:14:24 (20.3 MB/s) - ‘spark-2.4.1-bin-hadoop2.7.tgz’ saved [230778742/230778742]\n",
            "\n",
            "sample_data  spark-2.4.1-bin-hadoop2.7\tspark-2.4.1-bin-hadoop2.7.tgz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJX5_5BgwXQT",
        "colab_type": "text"
      },
      "source": [
        "# Set Environment Variables\n",
        "Set the locations where Spark and Java are installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOnW0ZNMwbiJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-2.4.1-bin-hadoop2.7\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlBYxETTwe73",
        "colab_type": "text"
      },
      "source": [
        "# Start a SparkSession\n",
        "This will start a local Spark session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PKo12Y9rwfx3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SQLContext\n",
        "\n",
        "conf = SparkConf().setMaster(\"local[*]\").setAppName('pyspark')\n",
        "sc = SparkContext(conf=conf)\n",
        "sqc = SQLContext(sc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3qfh3bPzxPdQ",
        "colab_type": "text"
      },
      "source": [
        "# Use Spark!\n",
        "That's all there is to it - you're ready to use Spark!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCpcQuU3x_MJ",
        "colab_type": "text"
      },
      "source": [
        "# Programming Ex\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnvLcGlm08m-",
        "colab_type": "text"
      },
      "source": [
        "Download File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VPUyVNyr0JQz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://data.sfgov.org/api/views/wr8u-xric/rows.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qee07QKn1QRJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1ec8732e-6e7a-4b36-9969-aef116989792"
      },
      "source": [
        "!ls -ltr /content/sample_data/\n",
        "\n",
        "#!head -10000 /content/drive/My\\ Drive/Data_Files/Fire_Department_Calls_for_Service_FULL.csv > Fire_Department_Calls_for_Service.csv\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 63512\n",
            "-rwxr-xr-x 1 root root      930 Jan  1  2000 README.md\n",
            "-rwxr-xr-x 1 root root     1697 Jan  1  2000 anscombe.json\n",
            "-rw-r--r-- 1 root root  1706430 Jun 10 16:28 california_housing_train.csv\n",
            "-rw-r--r-- 1 root root   301141 Jun 10 16:28 california_housing_test.csv\n",
            "-rw-r--r-- 1 root root 36523880 Jun 10 16:28 mnist_train_small.csv\n",
            "-rw-r--r-- 1 root root 18289443 Jun 10 16:28 mnist_test.csv\n",
            "-rw-r--r-- 1 root root     7640 Jun 14 12:17 movies_dataset.csv\n",
            "-rw-r--r-- 1 root root  3997368 Jun 14 13:03 Fire_Incidents.csv\n",
            "-rw-r--r-- 1 root root  4191435 Jun 14 13:04 Fire_Department_Calls_for_Service.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXtvviVx7_A9",
        "colab_type": "text"
      },
      "source": [
        "## San Francisco Fire Incidents (Meetup)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hjwZZ_Gk8C_y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 183
        },
        "outputId": "49a55d9a-0de4-4abe-93f6-a601f4e49508"
      },
      "source": [
        "fireServiceCallsDF = pyspark.read.csv('/content/sample_data/Fire_Department_Calls_for_Service.csv', header=True, inferSchema=True)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-41f767212561>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfireServiceCallsDF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpyspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/Fire_Department_Calls_for_Service.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'pyspark' is not defined"
          ]
        }
      ]
    }
  ]
}